#C:\Users\alexr\Desktop\dev\super_bot\smart_agent\executor\prompt_factory.py
import random
from typing import Optional, Dict, Any, List, Tuple, Set

from executor.ai_config import *


def create_prompt(
        style: str,
        room_type: str | None = None,
        furniture: str | None = None,
        plan_type: str | None = None
) -> str:
    base_prompt = PROMPT_INTERIOR_BASE

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª—É—á–∞–π–Ω–æ–≥–æ —Å—Ç–∏–ª—è
    if style == "üî• –°–ª—É—á–∞–π–Ω—ã–π –≤—ã–±–æ—Ä –ò–ò":
        available_styles = {k: v for k, v in STYLES_DETAIL.items() if v != "random_style"}
        random_style_name = random.choice(list(available_styles.keys()))
        style_text = available_styles[random_style_name]
    else:
        # –ï—Å–ª–∏ —Å—Ç–∏–ª—å –Ω–µ —Å–ª—É—á–∞–π–Ω—ã–π, –ø–æ–ª—É—á–∞–µ–º –µ–≥–æ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        style_text = STYLES_DETAIL.get(style, "modern style")

    # –°—Ü–µ–Ω–∞—Ä–∏–π "–î–∏–∑–∞–π–Ω –ø–ª–∞–Ω–∏—Ä–æ–≤–æ–∫"
    if plan_type:
        plan_text = PLAN_TYPE_PROMPTS.get(plan_type, "")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —à–∞–±–ª–æ–Ω –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        final_prompt = PROMPT_PLAN_DESIGN.format(
            plan_type=plan_text,
            style_text=style_text
        )

    # –°—Ü–µ–Ω–∞—Ä–∏–π "–†–µ–¥–∏–∑–∞–π–Ω –∏–Ω—Ç–µ—Ä—å–µ—Ä–∞"
    elif room_type and furniture is None:
        room_text = ROOM_TYPE_PROMPTS.get(room_type, "room")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —à–∞–±–ª–æ–Ω –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        final_prompt = PROMPT_REDESIGN.format(
            base_prompt=base_prompt,
            room_type=room_text,
            style_text=style_text
        )

    # –°—Ü–µ–Ω–∞—Ä–∏–π "–î–∏–∑–∞–π–Ω —Å –Ω—É–ª—è"
    elif room_type and furniture:
        room_text = ROOM_TYPE_PROMPTS.get(room_type, "room")
        furniture_text = FURNITURE_PROMPTS.get(furniture, "")
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —à–∞–±–ª–æ–Ω –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞
        final_prompt = PROMPT_ZERO_DESIGN.format(
            base_prompt=base_prompt,
            room_type=room_text,
            furniture_text=furniture_text,
            style_text=style_text
        )
    else:
        # –ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç
        final_prompt = f"{base_prompt}, {style_text}"

    # –û—á–∏—â–∞–µ–º –æ—Ç –ª–∏—à–Ω–∏—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –∑–∞–ø—è—Ç—ã—Ö
    return ", ".join(part.strip() for part in final_prompt.split(',') if part.strip())


def create_floor_plan_prompt(visualization_style: str, interior_style: str) -> str:
    base_instructions = FLOOR_PLAN_BASE_INSTRUCTIONS

    if visualization_style == 'sketch':
        visualization_block = FLOOR_PLAN_VISUALIZATION_SKETCH
    else:
        visualization_block = FLOOR_PLAN_VISUALIZATION_REALISTIC

    # ‚¨áÔ∏è –∑–¥–µ—Å—å –±—ã–ª–∞ –æ—à–∏–±–∫–∞: –±–ª–æ–∫ —Å {interior_style} –Ω–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–ª—Å—è
    final_instructions = FLOOR_PLAN_FINAL_INSTRUCTIONS.format(
        interior_style=interior_style
    )

    full_prompt = f"{base_instructions.strip()}\n\n{visualization_block.strip()}\n\n{final_instructions.strip()}"
    return full_prompt


#OPEN AI - –û–¢–†–ê–ë–û–¢–ö–ê –í–û–ó–†–ê–ñ–ï–ù–ò–ô –ö–õ–ò–ï–ù–¢–û–í
def build_objection_request(
    question: str,
    model: Optional[str] = None,
    temperature: float = 0.3,
    max_tokens: int = 700) -> Dict[str, Any]:
    """
    –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–æ–µ –º–µ—Å—Ç–æ, –≥–¥–µ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç—Å—è payload –¥–ª—è OpenAI Chat Completion.
    """
    system_prompt = OBJECTION_PROMPT_DEFAULT_RU
    use_model = model or OBJECTION_MODEL
    return {
        "model": use_model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": question},
        ],
    }


# --- –±—ã–ª–æ: build_description_request(question) ‚Äî –æ—Å—Ç–∞–≤–ª—è–µ–º –¥–ª—è –±—ç–∫–∞–ø–∞
def build_description_request(*, question: str, model: Optional[str] = None,
                              temperature: float = 0.7, max_tokens: int = 1200) -> Dict[str, Any]:
    system_prompt = DESCRIPTION_PROMPT_DEFAULT_RU
    use_model = model or DESCRIPTION_MODEL
    return {
        "model": use_model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": question},
        ],
    }

# --------- –ù–û–í–û–ï: —Å–±–æ—Ä–∫–∞ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Å—ã—Ä—ã—Ö –ø–æ–ª–µ–π ----------
def _label(m: Dict[str, str], key: Optional[str], default: str = "‚Äî") -> str:
    return m.get(key, default) if key else default

def _safe(val: Any) -> str:
    """
    –†–æ–±–∞—Å—Ç–Ω—ã–π safe-cast –≤ —Å—Ç—Ä–æ–∫—É –¥–ª—è –ª—é–±—ã—Ö —Ç–∏–ø–æ–≤:
      - None  -> "‚Äî"
      - int/float -> –∫–æ–º–ø–∞–∫—Ç–Ω–∞—è —Ñ–æ—Ä–º–∞ –±–µ–∑ —Ö–≤–æ—Å—Ç–∞ .0
      - bool -> "–î–∞"/"–ù–µ—Ç"
      - list/tuple/set -> —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–∫–∞–∂–¥—ã–π —ç–ª–µ–º–µ–Ω—Ç –ø—Ä–æ–≥–æ–Ω—è–µ—Ç—Å—è —á–µ—Ä–µ–∑ _safe)
      - –∏–Ω–æ–µ -> str().strip() —Å —Ñ–æ–ª–±—ç–∫–æ–º "‚Äî"
    """
    if val is None:
        return "‚Äî"
    if isinstance(val, (int, float)):
        try:
            return f"{val:.15g}"
        except Exception:
            return str(val)
    if isinstance(val, bool):
        return "–î–∞" if val else "–ù–µ—Ç"
    if isinstance(val, (list, tuple, set)):
        parts = [ _safe(x) for x in val ]
        parts = [ p for p in parts if p and p != "‚Äî" ]
        return ", ".join(parts) if parts else "‚Äî"
    s = str(val).strip()
    return s or "‚Äî"

def compose_description_user_message(fields: Dict[str, Optional[str]]) -> str:
    """
    –°–±–æ—Ä–∫–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —Å—ã—Ä—ã—Ö –ø–æ–ª–µ–π –ù–û–í–û–ô –∞–Ω–∫–µ—Ç—ã.
    –í—Å–µ —Å—Ç—Ä–æ–∫–∏/—á–∏—Å–ª–∞ –ø—Ä–∏–≤–æ–¥—è—Ç—Å—è –∫ –±–µ–∑–æ–ø–∞—Å–Ω–æ–º—É –≤–∏–¥—É; —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–µ –ª–µ–π–±–ª—ã
    –±–µ—Ä—É—Ç—Å—è –∏–∑ ai_config (DESCRIPTION_*).
    """
    t_key = fields.get("type")
    c_key = fields.get("apt_class") if t_key == "flat" else None
    x_key = fields.get("in_complex")
    a_key = fields.get("area")

    # –ß–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–µ –ø–æ–¥–ø–∏—Å–∏ (–¥–ª—è select'–æ–≤)
    type_label       = _label(DESCRIPTION_TYPES,   t_key)
    apt_class_label  = _label(DESCRIPTION_CLASSES, c_key) if c_key else "‚Äî"
    in_complex_label = _label(DESCRIPTION_COMPLEX, x_key)
    area_label       = _label(DESCRIPTION_AREA,    a_key)

    # –ù–æ–≤—ã–µ –ø–æ–ª—è –∞–Ω–∫–µ—Ç—ã (–∫–∞–∫ –µ—Å—Ç—å, –Ω–æ —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏)
    payload = {
        "type_label":       type_label,
        "apt_class_label":  apt_class_label,
        "in_complex_label": in_complex_label,
        "area_label":       area_label,
        "location":         _safe(fields.get("location")),
        "total_area":       _safe(fields.get("total_area")),
        "kitchen_area":     _safe(fields.get("kitchen_area")),
        "floor_number":     _safe(fields.get("floor_number")),
        "building_floors":  _safe(fields.get("building_floors")),
        "rooms":            _safe(fields.get("rooms")),
        "year_state":       _safe(fields.get("year_state")),
        "utilities":        _safe(fields.get("utilities")),   # CSV/—Å–ø–∏—Å–æ–∫/—Å–≤–æ–±–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        "amenities":        _safe(fields.get("amenities")),   # CSV/—Å–ø–∏—Å–æ–∫/—Å–≤–æ–±–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
        "comment":          _safe(fields.get("comment")),
    }

    # –ï–¥–∏–Ω—ã–π —à–∞–±–ª–æ–Ω –≤ ai_config ‚Äî –≤—Å–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω—ã —Ç–∞–º
    return DESCRIPTION_USER_TEMPLATE_RU.format(**payload)

def build_description_request_from_fields(
    *,
    fields: Dict[str, Optional[str]],
    model: Optional[str] = None,
    temperature: float = 0.7,
    max_tokens: int = 1200,
) -> Dict[str, Any]:
    """
    –ï–î–ò–ù–û–ï –º–µ—Å—Ç–æ —Å–±–æ—Ä–∫–∏ payload –∏–∑ —Å—ã—Ä—ã—Ö –ø–æ–ª–µ–π (–Ω–æ–≤–∞—è –∞–Ω–∫–µ—Ç–∞).
    –ö–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä –æ—Å—Ç–∞—ë—Ç—Å—è —Ç–æ–Ω–∫–∏–º.
    """
    user_message = compose_description_user_message(fields)
    system_prompt = DESCRIPTION_PROMPT_DEFAULT_RU
    use_model = model or DESCRIPTION_MODEL
    return {
        "model": use_model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message},
        ],
    }


# ===================== FEEDBACK / REVIEW =====================
_DEAL_TITLES = {
    "sale":              "–ü—Ä–æ–¥–∞–∂–∞",
    "buy":               "–ü–æ–∫—É–ø–∫–∞",
    "rent":              "–ê—Ä–µ–Ω–¥–∞",
    "mortgage":          "–ò–ø–æ—Ç–µ–∫–∞",
    "social_mortgage":   "–ì–æ—Å. –ø–æ–¥–¥–µ—Ä–∂–∫–∞",
    "maternity_capital": "–ú–∞—Ç–µ—Ä–∏–Ω—Å–∫–∏–π –∫–∞–ø–∏—Ç–∞–ª",
    "custom":            "–î—Ä—É–≥–æ–µ",
}

def _humanize_deal(deal_csv: Optional[str], custom: Optional[str]) -> str:
    codes = [c.strip() for c in (deal_csv or "").split(",") if c and c.strip()]
    names: List[str] = []
    for c in codes:
        if c == "custom":
            continue
        names.append(_DEAL_TITLES.get(c, c))
    if custom:
        names.append(f"–î—Ä—É–≥–æ–µ: {custom}")
    return ", ".join(names) if names else "‚Äî"

def _tone_label(key: Optional[str]) -> str:
    return FEEDBACK_TONES.get(key or "", "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π")

def _length_hint(key: Optional[str]) -> str:
    return FEEDBACK_LENGTH_HINTS.get(key or "", "–¥–æ ~450 –∑–Ω–∞–∫–æ–≤")

def _length_target_tokens(key: Optional[str]) -> int:
    # –ø—Ä–∏–±–ª–∏–∑–∏—Ç–µ–ª—å–Ω–æ: 1 —Ç–æ–∫–µ–Ω ~ 3‚Äì4 —Å–∏–º–≤–æ–ª–∞ –¥–ª—è RU; –¥–µ–ª–∞–µ–º —Å –∑–∞–ø–∞—Å–æ–º
    if key == "short":
        return 256
    if key == "long":
        return 900
    return 512  # medium


# –Ω–∏–∂–µ –±—ã–ª –¥—É–±–ª–∏–∫–∞—Ç _safe ‚Äî —É–¥–∞–ª—è–µ–º, —á—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ—Ç–∏—Ä–∞—Ç—å —Ä–æ–±–∞—Å—Ç–Ω—É—é –≤–µ—Ä—Å–∏—é –≤—ã—à–µ

def build_feedback_generate_request(*,
                                    fields: Dict[str, Optional[str]],
                                    num_variants: int = 3,
                                    model: Optional[str] = None,
                                    temperature: float = 0.6) -> Tuple[Dict[str, Any], Dict[str, Any]]:
    """
    –°–±–æ—Ä–∫–∞ payload –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —á–µ—Ä–Ω–æ–≤–∏–∫–æ–≤.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (payload –¥–ª—è OpenAI, debug_info).
    """
    # –ü–æ–¥–¥–µ—Ä–∂–∫–∞ —Å—Ç–∞—Ä–æ–≥–æ —Å—Ç–∏–ª—è (style) –∏ –Ω–æ–≤–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è (tone/length)
    tone_key   = fields.get("tone") or fields.get("style")  # back-compat
    length_key = fields.get("length") or ("long" if (fields.get("style") == "long") else ("short" if fields.get("style") == "brief" else "medium"))

    tone_label   = _tone_label(tone_key)
    length_hint  = _length_hint(length_key)
    max_tokens   = _length_target_tokens(length_key)
    deal_human   = _humanize_deal(fields.get("deal_type"), fields.get("deal_custom"))

    system_prompt = FEEDBACK_PROMPT_SYSTEM_RU
    user_message = FEEDBACK_USER_TEMPLATE_RU.format(
        client_name=_safe(fields.get("client_name")),
        agent_name=_safe(fields.get("agent_name")),
        company=_safe(fields.get("company")),
        city=_safe(fields.get("city")),
        address=_safe(fields.get("address")),
        deal_human=deal_human,
        situation=_safe(fields.get("situation")),
        tone=tone_label,
        style=_safe(fields.get("style")),
        length_hint=length_hint,
    )

    use_model = model or FEEDBACK_MODEL
    payload = {
        "model": use_model,
        "n": max(1, int(num_variants)),
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message},
        ],
    }
    debug = {
        "tone": tone_label,
        "length": length_key,
        "length_hint": length_hint,
        "deal_human": deal_human,
    }
    return payload, debug


def build_feedback_mutate_request(*,
                                  base_text: str,
                                  operation: str,            # 'short' | 'long' | 'style'
                                  style: Optional[str],
                                  tone: Optional[str],
                                  length: Optional[str],
                                  context: Dict[str, Optional[str]],
                                  model: Optional[str] = None,
                                  temperature: float = 0.5) -> Tuple[Dict[str, Any], Dict[str, Any]]:
    """
    –°–±–æ—Ä–∫–∞ payload –¥–ª—è –º—É—Ç–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞.
    """
    tone_key   = tone or style  # back-compat
    length_key = length

    tone_label  = _tone_label(tone_key)
    length_hint = _length_hint(length_key)
    max_tokens  = _length_target_tokens(length_key)
    deal_human  = _humanize_deal(context.get("deal_type"), context.get("deal_custom"))

    system_prompt = FEEDBACK_MUTATE_SYSTEM_RU

    instruction = ""
    if operation == "short":
        instruction = f"–°–æ–∫—Ä–∞—Ç–∏ —Ç–µ–∫—Å—Ç –¥–æ {length_hint} –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ —Å–º—ã—Å–ª–∞, —Å–æ—Ö—Ä–∞–Ω–∏–≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å."
    elif operation == "long":
        instruction = f"–†–∞—Å–∫—Ä–æ–π –∏ —Ä–∞—Å—à–∏—Ä—å —Ç–µ–∫—Å—Ç (–Ω–æ –±–µ–∑ ¬´–≤–æ–¥—ã¬ª) –¥–æ {length_hint}, —É—Å–∏–ª–∏–≤ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∏ CTA."
    elif operation == "style":
        instruction = f"–ü–µ—Ä–µ–ø–∏—à–∏ —Ç–µ–∫—Å—Ç –≤ —Ç–æ–Ω–µ: {tone_label}. –î–ª–∏–Ω–∞: {length_hint}."
    else:
        instruction = "–û—Ç—Ä–µ–¥–∞–∫—Ç–∏—Ä—É–π —Ç–µ–∫—Å—Ç, —Å–æ—Ö—Ä–∞–Ω–∏–≤ —Ñ–∞–∫—Ç—ã –∏ —É—Å–∏–ª–∏–≤ —É–±–µ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å."

    # user message
    user_message = FEEDBACK_MUTATE_USER_TEMPLATE_RU.format(
        instruction=instruction,
        base_text=base_text,
        client_name=_safe(context.get("client_name")),
        agent_name=_safe(context.get("agent_name")),
        company=_safe(context.get("company")),
        city=_safe(context.get("city")),
        address=_safe(context.get("address")),
        deal_human=deal_human,
        situation=_safe(context.get("situation")),
        tone=tone_label,
        length_hint=length_hint,
    )

    use_model = model or FEEDBACK_MODEL
    payload = {
        "model": use_model,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_message},
        ],
    }
    debug = {
        "operation": operation,
        "tone": tone_label,
        "length_hint": length_hint,
        "deal_human": deal_human,
    }
    return payload, debug


# –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –ª–∏–º–∏—Ç–µ—Ä –¥–ª–∏–Ω—ã
def _cut(s: str, n: int) -> str:
    s = s or ""
    return s if len(s) <= n else s[: n - 1]



# ------------------------------------------------------------------
# –ë–∏–ª–¥–µ—Ä –¥–ª—è —Å–∞–º–º–∞—Ä–∏ –ø–µ—Ä–µ–≥–æ–≤–æ—Ä–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ /summary/analyze)
# ------------------------------------------------------------------
def build_summary_analyze_request(
    *,
    transcript_text: str,
    model: str,
    prefer_language: Optional[str] = None,
    temperature: float = 0.2,
    max_tokens: int = 900,
) -> Tuple[Dict[str, Any], str]:
    """
    –°–æ–±–∏—Ä–∞–µ—Ç payload –¥–ª—è Chat Completions –≤ JSON-—Ñ–æ—Ä–º–∞—Ç–µ.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç —à–∞–±–ª–æ–Ω—ã –∏–∑ ai_config.py –∏ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–µ—Ç –ø–æ–ª—É—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (payload, debug_system_prompt).
    """
    lang = prefer_language or "the language of the conversation"

    # system: –∑–∞–¥–∞—á–∞ + —á–µ–∫-–ª–∏—Å—Ç + —Å—Ö–µ–º–∞ JSON
    sys_prompt = REALTY_SUMMARY_TASK_TMPL.format(
        CHECKLIST=REALTY_CHECKLIST,
        SCHEMA=REALTY_SUMMARY_JSON_SCHEMA,
        LANGUAGE=lang,
    )

    # user: —Å–∞–º —Ç–µ–∫—Å—Ç –¥–∏–∞–ª–æ–≥–∞ (–æ–±—Ä–µ–∑–∞–µ–º, —á—Ç–æ–±—ã –Ω–µ —É–ª–µ—Ç–µ—Ç—å –≤ –ª–∏–º–∏—Ç—ã)
    user_prompt = SUMMARY_ANALYZE_USER_TMPL.format(
        TEXT=_cut(transcript_text, 16000)
    )

    payload: Dict[str, Any] = {
        "model": model,
        "messages": [
            {"role": "system", "content": sys_prompt},
            {"role": "user",   "content": user_prompt},
        ],
        "response_format": {"type": "json_object"},
    }

    return payload, sys_prompt